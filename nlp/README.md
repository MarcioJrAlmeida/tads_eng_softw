## ğŸ§  AnÃ¡lise de Sentimento com Hugging Face Transformers
# ğŸ’¬ Sistema de AnÃ¡lise de ConteÃºdo Aberto - SADo

Este projeto tem como objetivo analisar automaticamente respostas textuais abertas de formulÃ¡rios, detectando **ofensas**, **crÃ­ticas construtivas**, **elogios**, **neutralidade** e **ironia**. Utilizamos **Machine Learning**, **modelos LLM**, e **estrutura modular em Python**, com armazenamento no **SQL Server**.

---

## ğŸ“‚ Estrutura do Projeto
nlp/
â”œâ”€â”€ config/
â”‚ â”œâ”€â”€ connection.py # ConexÃ£o com banco SQL Server
â”‚ â””â”€â”€ db_config_ml.py # ConfiguraÃ§Ãµes do banco para ML
â”‚
â”œâ”€â”€ ml/
â”‚ â”œâ”€â”€ database/
â”‚ â”‚ â””â”€â”€ datasets/ # Bases externas e CSVs para treino
â”‚ â”œâ”€â”€ interface/ # CLI para consultar resultados
â”‚ â”œâ”€â”€ learning/ # Treinamento dos modelos
â”‚ â”œâ”€â”€ modelos/ # Modelos salvos (.pkl)
â”‚ â”œâ”€â”€ preprocessing/ # PrÃ©-processamento e testes
â”‚ â””â”€â”€ validadores/ # FunÃ§Ãµes de anÃ¡lise (ML e LLM)
â”‚
â””â”€â”€ README.md

---

## ğŸ§  Modelos Treinados

### ğŸ”¸ Modelo de Ofensividade
- **Objetivo**: Detectar linguagem ofensiva/toxidade.
- **TÃ©cnica**: VetorizaÃ§Ã£o + `RandomForestClassifier`
- **Dataset**: 161.623 exemplos reais classificados manualmente.
- **Resultados**:
  - Accuracy: 1.00
  - Precision e Recall para True/False: 1.00
  - F1-score: 1.00

### ğŸ”¹ Modelo de Sentimento CrÃ­tico
- **Objetivo**: Identificar se a resposta Ã© crÃ­tica, elogiosa, irÃ´nica ou neutra.
- **TÃ©cnica**: VetorizaÃ§Ã£o + `RandomForestClassifier`
- **Classes**: `negativo`, `positivo`, `neutro`, `irÃ´nico`
- **Dataset**: 161.608 exemplos
- **Resultados**:
  - Accuracy: 0.97
  - Macro avg F1-score: 0.97

---

## ğŸ¤– LÃ³gica HÃ­brida (ML + LLM)

O arquivo `analise_texto_hibrido.py` combina:
- Resultados dos **modelos treinados (offline)** para escalabilidade
- Resultados de **modelos LLM externos (API IA)** para casos ambÃ­guos (com score entre 0.4 e 0.8)

---

## ğŸ” Testes Locais

Para testar o sistema localmente:

1. Execute os modelos de treino (caso necessÃ¡rio):
   ```bash
   python ml/learning/treinar_ofensivo.py
   python ml/learning/treinar_analise.py

2. FaÃ§a um teste manual de avaliaÃ§Ã£o:
  ```bash
  python ml/preprocessing/teste_analise_texto.py

## ğŸ—ƒï¸ Banco de Dados
- Utilizamos SQL Server com uma tabela central chamada Treinamento_Manual para alimentar os modelos.

- Outras tabelas de apoio:
  - Frases_Suspeitas
  - Frases_Analisadas

## ğŸ”— Modelos Utilizados
- âœ… Modelos personalizados via RandomForestClassifier

- ğŸ”„ LLMs integradas via API externa gratuita (com fallback)
  - Modelos base: cardiffnlp/twitter-roberta-base-sentiment, Bertimbau toxicidade
  - API: openai/gpt-3.5-turbo

## âš ï¸ Importante
- O uso de LLMs foi limitado apÃ³s testes devido ao custo elevado e polÃ­ticas de filtro de conteÃºdo ofensivo.

- O sistema segue operando com detecÃ§Ã£o 100% local, e a LLM sÃ³ atua via analise_texto_llm.py ou analise_texto_hibrido.py.

## ğŸ“ˆ Exemplos de Resultados
- Resultado do modelo ofensivo:
| Classe   | Precision | Recall | F1-score | Support |
| -------- | --------- | ------ | -------- | ------- |
| False    | 1.00      | 1.00   | 1.00     | 75.300  |
| True     | 1.00      | 1.00   | 1.00     | 86.323  |
| Accuracy |           |        | 1.00     | 161.623 |

- Resultado do modelo de sentimento:
| Classe   | Precision | Recall | F1-score | Support |
| -------- | --------- | ------ | -------- | ------- |
| IrÃ´nico  | 0.98      | 0.99   | 0.99     | 4.488   |
| Negativo | 1.00      | 0.94   | 0.97     | 92.403  |
| Neutro   | 0.99      | 0.99   | 0.99     | 4.553   |
| Positivo | 0.92      | 1.00   | 0.96     | 60.164  |
| Accuracy |           |        | 0.97     | 161.608 |

## ğŸ‘¨â€ğŸ’» Autor
Desenvolvido por MÃ¡rcioJr Almeida no contexto de processamento de linguagem natural (NLP) voltado para educaÃ§Ã£o e anÃ¡lise de formulÃ¡rios acadÃªmicos.

## ğŸ“Œ LicenÃ§a
Este projeto Ã© livre para fins acadÃªmicos e educativos.